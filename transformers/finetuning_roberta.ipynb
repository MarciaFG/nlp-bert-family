{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetuning_roberta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhRbQJ2+822fuMLRj9/+Am",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/branjbar/nlp-bert-family/blob/master/transformers/finetuning_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOkYyvysn0WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://huggingface.co/transformers/examples.html#roberta-bert-and-masked-language-modeling\n",
        "# https://www.kaggle.com/jihunlorenzopark/pretrain-with-another-twitter-dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M75gwNjNd1Jo",
        "colab_type": "code",
        "outputId": "ccf12f22-8d03-4054-e7c3-06ed64345780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Sat May  2 12:20:38 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xiYtgm-gGAM",
        "colab_type": "code",
        "outputId": "cae8a7e7-96d7-43fc-941a-34702cf7e238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 361, done.\u001b[K\n",
            "remote: Counting objects: 100% (361/361), done.\u001b[K\n",
            "remote: Compressing objects: 100% (189/189), done.\u001b[K\n",
            "remote: Total 26096 (delta 178), reused 322 (delta 163), pack-reused 25735\u001b[K\n",
            "Receiving objects: 100% (26096/26096), 15.38 MiB | 14.35 MiB/s, done.\n",
            "Resolving deltas: 100% (18222/18222), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyvgfYz9iTKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "8d07a190-4027-4e6a-ea35-38a6b967235d"
      },
      "source": [
        "import os\n",
        "os.chdir(\"transformers\")\n",
        "!pip install ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.3)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 28.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.14.1)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.8.0-cp36-none-any.whl size=595726 sha256=93508cc47e01a6f1a612b9d151ec28de0b9ae8db37ea7ce91519c8c9c2b0e90e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_zskg9s2/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=fb31c0c8c694fc377da5bbbcd56fb3b433c02755c67aed9f198ac5ce239376ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.7.0 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE48c5YAle4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-raw-v1.zip\n",
        "# !unzip wikitext-2-raw-v1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6g3HHcIepjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python examples/run_language_modeling.py \\\n",
        "#     --output_dir=output \\\n",
        "#     --model_type=roberta \\\n",
        "#     --model_name_or_path=roberta-base \\\n",
        "#     --do_train \\\n",
        "#     --train_data_file=wikitext-2-raw/wiki.test.raw \\\n",
        "#     --do_eval \\\n",
        "#     --eval_data_file=wikitext-2-raw/wiki.test.raw \\\n",
        "#     --mlm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyO4R7uuP4Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd, re, numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPUjT5xWpPty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KAGGLE_INPUT_PATH = \"../input/\"\n",
        "COLAB_INPUT_PATH = \"/content/drive/My Drive/input/\"\n",
        "INPUT_PATH = COLAB_INPUT_PATH\n",
        "\n",
        "DATA_PATH = INPUT_PATH + \"tweet-sentiment-extraction/\"\n",
        "CHECKPOINT_PATH = INPUT_PATH + \"model_checkpoint/roberta/\"\n",
        "ROBERTA_PATH = INPUT_PATH + 'tf-roberta/'\n",
        "EMOTION_PATH = INPUT_PATH + 'training-data/emotion/text_emotion.csv'\n",
        "SENTIMENT140_PATH = INPUT_PATH + 'training-data/sentiment140/training.1600000.processed.noemoticon.csv'\n",
        "TWITTER_SENTIMENTS_PATH = INPUT_PATH + 'training-data/twitter-sentiment/Sentiment Analysis Dataset 2.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW5LazApUcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_html(text):\n",
        "    text = re.sub(\"&quot;\", '\"', text)\n",
        "    text = re.sub(\"&gt;\", \">\", text)\n",
        "    text = re.sub(\"&lt;\", \"<\", text)\n",
        "    text = re.sub(\"&le;\", \"≤\", text)\n",
        "    text = re.sub(\"&ge;\", \"≥\", text)\n",
        "    text = re.sub(\"&amp;\", \"&\", text)\n",
        "    return text\n",
        "\n",
        "def remove_twitter_id(text):\n",
        "    text = text.strip()\n",
        "    text = \" \".join([i for i in text.split(\" \") if \"@\" not in i])\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "def to_text(df, filename):\n",
        "    f = open(filename, 'w')\n",
        "    for c in df[\"content\"].values:\n",
        "        f.write(\" \" + c.strip() + \"\\n\\n\")\n",
        "    f.close()\n",
        "\n",
        "def pandas_to_train_test_file(df, filename):\n",
        "    df_train, df_test = train_test_split(df, test_size=0.1, random_state=333)\n",
        "    to_text(df_train, \"../%s.train.txt\"%filename)\n",
        "    to_text(df_test, \"../%s.test.txt\"%filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYFpslP5qFuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cec4b631-58a9-4312-8eeb-f4194b33f114"
      },
      "source": [
        "emotion_df = pd.read_csv(EMOTION_PATH)\n",
        "emotion_df['content'] = emotion_df['content'].astype(str).str.lower()\n",
        "emotion_df[\"content\"] = emotion_df[\"content\"].apply(remove_html)\n",
        "emotion_df[\"content\"] = emotion_df[\"content\"].apply(remove_twitter_id)\n",
        "emotion_df = emotion_df[[\"content\"]]\n",
        "print(emotion_df.shape[0])\n",
        "emotion_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i know  i was listenin to bad habit earlier an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wants to hang out with friends soon!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we want to trade with someone who has houston ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content\n",
              "0  i know  i was listenin to bad habit earlier an...\n",
              "1  layin n bed with a headache  ughhhh...waitin o...\n",
              "2                funeral ceremony...gloomy friday...\n",
              "3               wants to hang out with friends soon!\n",
              "4  we want to trade with someone who has houston ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DxJlucKWGyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4d0c2ea5-1025-4827-812c-278f844c6455"
      },
      "source": [
        "sentiment140_df = pd.read_csv(SENTIMENT140_PATH, encoding = \"ISO-8859-1\", engine='python', header=None)\n",
        "sentiment140_df.columns = [0, 1, 2, 3, 4, \"content\"]\n",
        "sentiment140_df['content'] = sentiment140_df['content'].astype(str).str.lower()\n",
        "sentiment140_df[\"content\"] = sentiment140_df[\"content\"].apply(remove_html)\n",
        "sentiment140_df[\"content\"] = sentiment140_df[\"content\"].apply(remove_twitter_id)\n",
        "sentiment140_df = sentiment140_df[[\"content\"]]\n",
        "print(sentiment140_df.shape[0])\n",
        "sentiment140_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://twitpic.com/2y1zl - awww, that's a bumm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i dived many times for the ball. managed to sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content\n",
              "0  http://twitpic.com/2y1zl - awww, that's a bumm...\n",
              "1  is upset that he can't update his facebook by ...\n",
              "2  i dived many times for the ball. managed to sa...\n",
              "3     my whole body feels itchy and like its on fire\n",
              "4  no, it's not behaving at all. i'm mad. why am ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd_1esW_WyIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f3d19733-68b2-4b5e-dfe0-95e37312ad83"
      },
      "source": [
        "twitter_df = pd.read_csv(TWITTER_SENTIMENTS_PATH, error_bad_lines=False)\n",
        "twitter_df.columns = [0, 1, 2, \"content\"]\n",
        "twitter_df['content'] = twitter_df['content'].astype(str).str.lower()\n",
        "twitter_df[\"content\"] = twitter_df[\"content\"].apply(remove_html)\n",
        "twitter_df[\"content\"] = twitter_df[\"content\"].apply(remove_twitter_id)\n",
        "twitter_df = twitter_df[[\"content\"]]\n",
        "print(twitter_df.shape[0])\n",
        "twitter_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
            "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1578612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is so sad for my apl friend.............</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i missed the new moon trailer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>omg its already 7:30 :o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.. omgaga. im sooo  im gunna cry. i've been at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i think mi bf is cheating on me!!!       t_t</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content\n",
              "0           is so sad for my apl friend.............\n",
              "1                   i missed the new moon trailer...\n",
              "2                            omg its already 7:30 :o\n",
              "3  .. omgaga. im sooo  im gunna cry. i've been at...\n",
              "4       i think mi bf is cheating on me!!!       t_t"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGd7WwzSZeFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "34762f44-ec50-4f0e-8d56-21382a6c853e"
      },
      "source": [
        "full_df = pd.concat([emotion_df, sentiment140_df, twitter_df])\n",
        "print(full_df.shape)\n",
        "pandas_to_train_test_file(full_df, \"twitter_3m\")\n",
        "full_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3218612, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i know  i was listenin to bad habit earlier an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wants to hang out with friends soon!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we want to trade with someone who has houston ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content\n",
              "0  i know  i was listenin to bad habit earlier an...\n",
              "1  layin n bed with a headache  ughhhh...waitin o...\n",
              "2                funeral ceremony...gloomy friday...\n",
              "3               wants to hang out with friends soon!\n",
              "4  we want to trade with someone who has houston ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO3T2JHmo3KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python examples/run_language_modeling.py \\\n",
        "#     --output_dir=../roberta-tmp \\\n",
        "#     --model_type=roberta \\\n",
        "#     --model_name_or_path=roberta-base \\\n",
        "#     --do_train \\\n",
        "#     --train_data_file=../emotion.train.txt \\\n",
        "#     --do_eval \\\n",
        "#     --eval_data_file=../emotion.test.txt \\\n",
        "#     --mlm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do1tA3RXs21k",
        "colab_type": "code",
        "outputId": "6e13fd6e-b3c3-4699-d7ea-28a0fd2a24f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python examples/run_language_modeling.py \\\n",
        "    --output_dir='/content/drive/My Drive/input/models/roberta-twitter3m' \\\n",
        "    --model_type=roberta \\\n",
        "    --model_name_or_path=roberta-base \\\n",
        "    --do_train \\\n",
        "    --train_data_file=../twitter_3m.train.txt \\\n",
        "    --do_eval \\\n",
        "    --eval_data_file=../twitter_3m.test.txt \\\n",
        "    --save_steps=0 \\\n",
        "    --mlm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-02 12:22:43.455656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/02/2020 12:22:46 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
            "05/02/2020 12:22:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "05/02/2020 12:22:46 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/content/drive/My Drive/input/models/roberta-twitter3m', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir=None, logging_first_step=False, logging_steps=500, save_steps=0, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1)\n",
            "05/02/2020 12:22:46 - INFO - filelock -   Lock 140074460229304 acquired on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock\n",
            "05/02/2020 12:22:46 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpc8x4klpi\n",
            "Downloading: 100% 481/481 [00:00<00:00, 348kB/s]\n",
            "05/02/2020 12:22:47 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json in cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "05/02/2020 12:22:47 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "05/02/2020 12:22:47 - INFO - filelock -   Lock 140074460229304 released on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock\n",
            "05/02/2020 12:22:47 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "05/02/2020 12:22:47 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "05/02/2020 12:22:47 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "05/02/2020 12:22:47 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "05/02/2020 12:22:47 - INFO - filelock -   Lock 140074460228800 acquired on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n",
            "05/02/2020 12:22:47 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpdj2anrpe\n",
            "Downloading: 100% 899k/899k [00:00<00:00, 1.82MB/s]\n",
            "05/02/2020 12:22:48 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "05/02/2020 12:22:48 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "05/02/2020 12:22:48 - INFO - filelock -   Lock 140074460228800 released on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n",
            "05/02/2020 12:22:49 - INFO - filelock -   Lock 140074460226000 acquired on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "05/02/2020 12:22:49 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmprcm0k2tl\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 1.38MB/s]\n",
            "05/02/2020 12:22:50 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "05/02/2020 12:22:50 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "05/02/2020 12:22:50 - INFO - filelock -   Lock 140074460226000 released on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "05/02/2020 12:22:50 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "05/02/2020 12:22:50 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "05/02/2020 12:22:51 - INFO - filelock -   Lock 140074460228968 acquired on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n",
            "05/02/2020 12:22:51 - INFO - transformers.file_utils -   https://cdn.huggingface.co/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp96nlwsps\n",
            "Downloading: 100% 501M/501M [00:10<00:00, 47.6MB/s]\n",
            "05/02/2020 12:23:02 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/roberta-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "05/02/2020 12:23:02 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "05/02/2020 12:23:02 - INFO - filelock -   Lock 140074460228968 released on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n",
            "05/02/2020 12:23:02 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "05/02/2020 12:23:11 - INFO - transformers.modeling_utils -   Weights of RobertaForMaskedLM not initialized from pretrained model: ['lm_head.decoder.bias']\n",
            "05/02/2020 12:23:11 - INFO - transformers.data.datasets.language_modeling -   Creating features from dataset file at ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbpcW7g-Z90D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}