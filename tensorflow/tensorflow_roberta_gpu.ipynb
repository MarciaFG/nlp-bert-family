{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_roberta_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHFRpak+y9dOJoAmih72hA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/branjbar/nlp-bert-family/blob/master/tensorflow/tensorflow_roberta_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okm4ne1CV7av",
        "colab_type": "code",
        "outputId": "f43b81ab-f303-4f3c-9028-b93e0f79e980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# To avoid notebook get disconnected\n",
        "\"\"\"\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button\").click() \n",
        "}setInterval(ClickConnect,60000)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "caffeinate\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncaffeinate\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VmEWu6QwCLX",
        "colab_type": "code",
        "outputId": "58fc06cd-2181-4dd1-80e9-09b94840f1ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Tue Apr 28 12:23:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UODiXfmptdMd",
        "colab_type": "text"
      },
      "source": [
        "TODOs:\n",
        "- different head for start and end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGTHRzFTwKSI",
        "colab_type": "code",
        "outputId": "96ed4d62-a56d-4a16-bb66-7eaed93fcc75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!pip install transformers\n",
        "import os\n",
        "import pandas as pd, numpy as np\n",
        "import time, re, math\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import *\n",
        "import tokenizers\n",
        "print('TF version',tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "TF version 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adF-Or6QwwQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KAGGLE_INPUT_PATH = \"../input/\"\n",
        "COLAB_INPUT_PATH = \"/content/drive/My Drive/input/\"\n",
        "INPUT_PATH = COLAB_INPUT_PATH\n",
        "\n",
        "DATA_PATH = INPUT_PATH + \"tweet-sentiment-extraction/\"\n",
        "CHECKPOINT_PATH = INPUT_PATH + \"model_checkpoint/roberta/\"\n",
        "ROBERTA_PATH = INPUT_PATH + 'tf-roberta/'\n",
        "EMOTION_PATH = INPUT_PATH + 'emotion/'\n",
        "\n",
        "VER='v7'\n",
        "DISPLAY=1 # USE display=1 FOR INTERACTIVE\n",
        "\n",
        "DEV_MODE = False # if True only looks at a subset of data\n",
        "MAX_MULT_PROB = False \n",
        "AUGMENT_DATA = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2TdPHvh4XdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_html(text):\n",
        "    text = re.sub(\"&quot;\", '\"', text)\n",
        "    text = re.sub(\"&gt;\", \">\", text)\n",
        "    text = re.sub(\"&lt;\", \"<\", text)\n",
        "    text = re.sub(\"&le;\", \"≤\", text)\n",
        "    text = re.sub(\"&ge;\", \"≥\", text)\n",
        "    text = re.sub(\"&amp;\", \"&\", text)\n",
        "    return text\n",
        "\n",
        "def add_html(text):\n",
        "    text = re.sub('\"', \"&quot;\",  text)\n",
        "    text = re.sub(\">\", \"&gt;\", text)\n",
        "    text = re.sub(\"<\", \"&lt;\", text)\n",
        "    text = re.sub(\"≤\", \"&le;\", text)\n",
        "    text = re.sub(\"≥\", \"&ge;\", text)\n",
        "    text = re.sub(\"&\", \"&amp;\", text)   \n",
        "    return text\n",
        "#TODO: find examples and apply!!\n",
        "\n",
        "def print_to_file(text):\n",
        "  try:\n",
        "    f = open(CHECKPOINT_PATH + VER + \"_logs.txt\", 'a')\n",
        "  except:\n",
        "    f = open(CHECKPOINT_PATH + VER + \"_logs.txt\", 'w')\n",
        "\n",
        "  print(text)\n",
        "  f.write(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  f.write(\"  -- \")\n",
        "  f.write(text)\n",
        "  f.write(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUXCviVTxAk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard(str1, str2): \n",
        "\n",
        "    a = set(str(str1).lower().split()) \n",
        "    b = set(str(str2).lower().split())\n",
        "\n",
        "    c = a.intersection(b)\n",
        "\n",
        "    if (len(a) + len(b) - len(c)) > 0:\n",
        "      return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoajiefWxWQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 120 #96 #TODO: make this value high enough that this doesn't cause an issue in the final setting\n",
        "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
        "    vocab_file= ROBERTA_PATH +'vocab-roberta-base.json', \n",
        "    merges_file= ROBERTA_PATH +'merges-roberta-base.txt', \n",
        "    lowercase=True,\n",
        "    add_prefix_space=True\n",
        ")\n",
        "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUVVzLs500Xc",
        "colab_type": "text"
      },
      "source": [
        "# READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiXCCJOSwnv5",
        "colab_type": "code",
        "outputId": "f844833e-df5b-4a02-fcc9-e5392cc8593f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def read_train():\n",
        "    train=pd.read_csv(DATA_PATH + 'train.csv')\n",
        "    train['text']=train['text'].astype(str)\n",
        "    train['selected_text']=train['selected_text'].astype(str)\n",
        "\n",
        "    return train\n",
        "\n",
        "def read_test():\n",
        "    test=pd.read_csv(DATA_PATH + 'test.csv')\n",
        "    test['text']=test['text'].astype(str)\n",
        "\n",
        "    return test\n",
        "    \n",
        "def read_emotion():\n",
        "    emotion=pd.read_csv(EMOTION_PATH + 'text_emotion.csv')\n",
        "    emotion['content']=emotion['content'].astype(str)\n",
        "\n",
        "    return emotion\n",
        "\n",
        "def enrich_data(train_df_original, emotion_df):\n",
        "\n",
        "\n",
        "    train_df_original[\"source\"] = \"competition\"\n",
        "\n",
        "    train_df_neutral = pd.DataFrame()\n",
        "    train_df_neutral[\"text\"] = emotion_df[emotion_df.sentiment == \"neutral\"].content\n",
        "    train_df_neutral[\"text\"] = train_df_neutral[\"text\"].apply(lambda x: \" \".join([i for i in x.split(\" \") if \"@\" not in i]))\n",
        "    train_df_neutral[\"text\"] = train_df_neutral[\"text\"].apply(remove_html)\n",
        "    train_df_neutral[\"selected_text\"] = train_df_neutral[\"text\"]\n",
        "    train_df_neutral[\"textID\"] = None\n",
        "    train_df_neutral[\"sentiment\"] = \"neutral\"\n",
        "    train_df_neutral[\"source\"] = \"emotion\"\n",
        "\n",
        "    \n",
        "    # compensate for the newly added neutral samples\n",
        "    a = (train_df_original.sentiment == \"neutral\").sum()\n",
        "    b = (train_df_original.sentiment == \"positive\").sum()\n",
        "    c = (train_df_original.sentiment == \"negative\").sum()\n",
        "    x = (train_df_neutral.sentiment == \"neutral\").sum()\n",
        "    y = math.floor(((a + x) * b / a) - b)\n",
        "    z = math.floor(((a + x) * c / a) - c)\n",
        "\n",
        "    train_df_comp_positive = train_df_original[train_df_original.sentiment==\"positive\"].sample(n=y,random_state=777)\n",
        "    train_df_comp_negative = train_df_original[train_df_original.sentiment==\"negative\"].sample(n=z,random_state=777)\n",
        "    # train_df_comp_positive[\"text\"] = train_df_comp_positive[\"selected_text\"] \n",
        "    # train_df_comp_negative[\"text\"] = train_df_comp_negative[\"selected_text\"] \n",
        "    train_df_comp_positive[\"source\"] = \"compensation\"\n",
        "    train_df_comp_negative[\"source\"] = \"compensation\"    \n",
        "    \n",
        "    train_df = pd.concat([train_df_original, train_df_neutral, train_df_comp_positive, train_df_comp_negative]).reset_index()\n",
        "    return train_df\n",
        "\n",
        "if (DEV_MODE == True):\n",
        "  train_df_original = read_train().sample(frac=.05, random_state=1).reset_index()\n",
        "  test_df = read_test().sample(frac=.05, random_state=1).reset_index()\n",
        "else:\n",
        "  train_df_original = read_train()\n",
        "  test_df = read_test()\n",
        "\n",
        "emotion_df_original = read_emotion()\n",
        "\n",
        "if AUGMENT_DATA:\n",
        "    train_df = enrich_data(train_df_original.copy(), emotion_df_original)\n",
        "else:\n",
        "    train_df = train_df_original.copy()\n",
        "    train_df[\"source\"] = \"competition\"\n",
        "\n",
        "print_to_file(\"train_df_original shape:\" + str(train_df_original.shape))\n",
        "print_to_file(\"emotion_df_original shape:\" + str(emotion_df_original.shape))\n",
        "\n",
        "print_to_file(\"train_df shape:\" + str(train_df.shape))\n",
        "print_to_file(\"test_df shape:\" + str(test_df.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_df_original shape:(27481, 4)\n",
            "emotion_df_original shape:(40000, 4)\n",
            "train_df shape:(27481, 5)\n",
            "test_df shape:(3534, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYedSrGP0x3u",
        "colab_type": "text"
      },
      "source": [
        "# PREPROCESS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS9Q043XxfFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct = train_df.shape[0]\n",
        "input_ids = np.ones((ct,MAX_LEN),dtype='int32')\n",
        "attention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "token_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "start_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "end_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "\n",
        "for k in range(train_df.shape[0]):\n",
        "    \n",
        "    # FIND OVERLAP\n",
        "    text1 = \" \"+\" \".join(train_df.loc[k,'text'].split())\n",
        "    text2 = \" \".join(train_df.loc[k,'selected_text'].split())\n",
        "    idx = text1.find(text2)\n",
        "    chars = np.zeros((len(text1)))\n",
        "    chars[idx:idx+len(text2)]=1\n",
        "    if text1[idx-1]==' ': chars[idx-1] = 1 \n",
        "    enc = tokenizer.encode(text1) \n",
        "        \n",
        "    # ID_OFFSETS\n",
        "    offsets = []; idx=0\n",
        "    for t in enc.ids:\n",
        "        w = tokenizer.decode([t])\n",
        "        offsets.append((idx,idx+len(w)))\n",
        "        idx += len(w)\n",
        "    \n",
        "    # START END TOKENS\n",
        "    toks = []\n",
        "    for i,(a,b) in enumerate(offsets):\n",
        "        sm = np.sum(chars[a:b])\n",
        "        if sm>0: toks.append(i) \n",
        "        \n",
        "    s_tok = sentiment_id[train_df.loc[k,'sentiment']]\n",
        "    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
        "    attention_mask[k,:len(enc.ids)+5] = 1\n",
        "    if len(toks)>0:\n",
        "        start_tokens[k,toks[0]+1] = 1\n",
        "        end_tokens[k,toks[-1]+1] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDe1YBS7wOc-",
        "colab_type": "code",
        "outputId": "c1559bbc-e02a-476e-cc98-49d6df9e881d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "emotion_df_original.sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUHrroTluxMB",
        "colab_type": "code",
        "outputId": "3c9e4a5a-d19b-4b2e-a651-3b7b15184134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "emotion_df = emotion_df_original[emotion_df_original.sentiment!=\"empty\"].reset_index()\n",
        "emotion_id = {}\n",
        "for i, s in enumerate(emotion_df.sentiment.unique()):\n",
        "    emotion_id[s] = i\n",
        "print(emotion_id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sadness': 0, 'enthusiasm': 1, 'neutral': 2, 'worry': 3, 'surprise': 4, 'love': 5, 'fun': 6, 'hate': 7, 'happiness': 8, 'boredom': 9, 'relief': 10, 'anger': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZHT_8eauIII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct = emotion_df.shape[0]\n",
        "input_ids_e = np.ones((ct,MAX_LEN),dtype='int32')\n",
        "attention_mask_e = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "token_type_ids_e = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "emotion_class = np.zeros((ct),dtype='int32')\n",
        "\n",
        "for k in range(ct):\n",
        "    \n",
        "    # FIND OVERLAP\n",
        "    text = \" \"+\" \".join(emotion_df.loc[k,'content'].split())\n",
        "    enc = tokenizer.encode(text)                \n",
        "    s_tok = emotion_id[emotion_df.loc[k,'sentiment']]\n",
        "    input_ids_e[k,:len(enc.ids)+2] = [0] + enc.ids + [2]\n",
        "    attention_mask_e[k,:len(enc.ids)+2] = 1 \n",
        "    emotion_class[k] = s_tok"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c740MhN9xfpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct = test_df.shape[0]\n",
        "input_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\n",
        "attention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "token_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "\n",
        "for k in range(test_df.shape[0]):\n",
        "        \n",
        "    # INPUT_IDS\n",
        "    text1 = \" \"+\" \".join(test_df.loc[k,'text'].split())\n",
        "    enc = tokenizer.encode(text1)                \n",
        "    s_tok = sentiment_id[test_df.loc[k,'sentiment']]\n",
        "    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
        "    attention_mask_t[k,:len(enc.ids)+5] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkz0f3CPeQAU",
        "colab_type": "text"
      },
      "source": [
        "# FINE TUNE RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xAG3s70fNhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import metrics\n",
        "\n",
        "def build_classifcation_model():\n",
        "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "\n",
        "    config = RobertaConfig.from_pretrained(ROBERTA_PATH + 'config-roberta-base.json')\n",
        "    bert_model = TFRobertaModel.from_pretrained(ROBERTA_PATH + 'pretrained-roberta-base.h5',config=config)\n",
        "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
        "    \n",
        "    \n",
        "    x = tf.keras.layers.Dropout(0.1)(x[0]) \n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x) \n",
        "    # x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(len(emotion_id.values()), activation=\"sigmoid\")(x)\n",
        "    x = tf.keras.layers.Activation(\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x])\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JLx4EV9lXCs",
        "colab_type": "code",
        "outputId": "c84497de-b8b0-4444-f3ca-712bbd1da085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model_classifier = build_classifcation_model()\n",
        "model_classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 120)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 120)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 120)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model_1 (TFRobertaMo ((None, 120, 768), ( 124645632   input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 120, 768)     0           tf_roberta_model_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 768)          0           dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 768)          0           global_average_pooling1d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 12)           9228        dropout_79[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 124,654,860\n",
            "Trainable params: 124,654,860\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn6gC3M2kZu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e_df, e_df_valid, X1, X1_valid, X2, X2_valid, X3, X3_valid, Y, Y_valid = model_selection.train_test_split(\n",
        "    emotion_df,\n",
        "    input_ids_e, attention_mask_e, token_type_ids_e, emotion_class,\n",
        "    test_size=0.1, random_state=333\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6RLMy44w99z",
        "colab_type": "code",
        "outputId": "a1cb446a-6c00-43d1-9642-274ef7db35c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn import model_selection\n",
        "e_df, e_df_valid, X1, X1_valid, X2, X2_valid, X3, X3_valid, Y, Y_valid = model_selection.train_test_split(\n",
        "    emotion_df,\n",
        "    input_ids_e, attention_mask_e, token_type_ids_e, emotion_class,\n",
        "    test_size=0.1, random_state=333\n",
        "    )\n",
        "\n",
        "X = [X1, X2, X3]\n",
        "X_valid = [X1_valid, X2_valid, X3_valid]\n",
        "K.clear_session()\n",
        "model_classifier.fit(\n",
        "    X,\n",
        "    Y,\n",
        "    epochs=2,\n",
        "    batch_size=16, #8,\n",
        "    verbose=DISPLAY,\n",
        "    validation_data=(X_valid, Y_valid)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2204/2204 [==============================] - 577s 262ms/step - loss: 1.7887 - acc: 0.3783 - val_loss: 1.7346 - val_acc: 0.3885\n",
            "Epoch 2/2\n",
            "2204/2204 [==============================] - 574s 261ms/step - loss: 1.6643 - acc: 0.4224 - val_loss: 1.7327 - val_acc: 0.3989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f119ef91470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3NZ3845Zobp",
        "colab_type": "code",
        "outputId": "1e278457-00c5-4e38-bcb1-03d2baaf229a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model_classifier.fit(\n",
        "    X,\n",
        "    Y,\n",
        "    epochs=2,\n",
        "    batch_size=16, #8,\n",
        "    verbose=DISPLAY,\n",
        "    validation_data=(X_valid, Y_valid)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2204/2204 [==============================] - 573s 260ms/step - loss: 1.5722 - acc: 0.4498 - val_loss: 1.7726 - val_acc: 0.3885\n",
            "Epoch 2/2\n",
            "2204/2204 [==============================] - 575s 261ms/step - loss: 1.4592 - acc: 0.4879 - val_loss: 1.8202 - val_acc: 0.3903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f119b14de10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEai6AGJtitm",
        "colab_type": "code",
        "outputId": "6202fc28-2e0b-474b-f757-1ee5c312c2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "CHECKPOINT_PATH + \"finetuned-roberta_pretrained/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/input/model_checkpoint/roberta/finetuned-roberta_pretrained/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQC7-bO-XwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_roberta_model = model_classifier.layers[3]\n",
        "new_roberta_model._name = \"fine-tuned_roberta\"\n",
        "#new_roberta_model.save_weights(CHECKPOINT_PATH + 'finetuned-roberta_midsize.h5')\n",
        "new_roberta_model.save_pretrained(CHECKPOINT_PATH + 'finetuned_roberta_pretrained/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNbOrRCytuCU",
        "colab_type": "code",
        "outputId": "5d595cce-e524-4b49-8e1a-77205d18840f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.path.isdir(CHECKPOINT_PATH + 'finetuned_roberta_pretrained/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPFYBD49-ycT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_classifier.save_weights(CHECKPOINT_PATH + 'finetuned-roberta_classifier.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrGPkTyw3dzV",
        "colab_type": "code",
        "outputId": "9a4a0c39-69a5-4adf-f8eb-01e6050b2ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print_to_file(\"evaluation of fine-tuning model.\")\n",
        "print_to_file(str(model_classifier.evaluate(X_valid, Y_valid)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluation of fine-tuning model.\n",
            "123/123 [==============================] - 20s 165ms/step - loss: 1.8207 - acc: 0.3903\n",
            "[1.8207457065582275, 0.3902501165866852]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OtRXbwAkK81",
        "colab_type": "code",
        "outputId": "34fb0c77-79a9-49bb-826c-6e68cc1412ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "z = model_classifier.predict(X_valid)\n",
        "predicted_emotions = np.argmax(z, axis=1)\n",
        "e_df_valid = e_df_valid.reset_index()\n",
        "emotion_id_reverse = dict((v,k) for k,v in emotion_id.items())\n",
        "\n",
        "for k in range(5):\n",
        "    print(e_df_valid.loc[k].content, \"<----\",emotion_id_reverse[predicted_emotions[k]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "looked up weather for greece this weekend....80 and sunny OMGZ <---- happiness\n",
            "@werewolfembry heyy <---- neutral\n",
            "Glad to see the sun out in Dublin after a great week in London. Back to work <---- happiness\n",
            "@rdkpickle For the movie, but maybe I am just a little awesome. <---- happiness\n",
            "Dead stopped in the express lane. This would happen when I choose to take it. No way out now. Ugh. Hopefully this gets moving <---- worry\n",
            "YAY! My temperature went down!  I can have dinner with the family tonight. <---- happiness\n",
            "Mattcutts.com: Domain Umzug und neues Design http://redir.ec/iF2b ... <---- neutral\n",
            "i didn't wake up early enough to go roller blading  contrary to a tributary, i flow endlessly <---- worry\n",
            "@susannaheanes bwaha! It's so far away, though.  But it looks fluffy! And Jared's hair's SHINNNY. <---- happiness\n",
            "Anybody have advice on who to use for printing biz cards besides Overnight (bad experience) &amp; PsPrint, each biz card = sep. project = <---- worry\n",
            "Signing off to spend time with my hubby   Goodnight / day tweeple!   Have a very Happy Mother's Day! <---- love\n",
            "@FreyaLynn lol seriously.  fail. ::sigh:: <---- worry\n",
            "@andcasey lol we should start a group lol the slut sisters <---- fun\n",
            "So theres this boy. Hes so cute. Hes got a six pack.  yum it was fun touchin it. <---- love\n",
            "@quinland  I Hate It There Should Be A Endless Supply Of Hot Water!  I Put the Water Heater On 20mins Ago So Ill Be Gone In 10mins  Xx <---- hate\n",
            "Jane is really sad because she probably won't get perfect on tonight's quiz without the missing article. Should've asked someone for it. <---- worry\n",
            "great night <---- neutral\n",
            "Just got confirmed that itï¿½s pizza-time with some ex co-workers on friday...looking forward to it <---- happiness\n",
            "Girsl night ! on my way to foam party  No sleep tonight !! <---- happiness\n",
            "@therami well, so are you  but i managed to go to sleep for another couple of hours and wake up again while you're still snoozing <---- neutral\n",
            "@rookiepaul that doesnt sound like a good situation <---- worry\n",
            "In French trois, nobody is sitting next to me. I feel a little lonely... <---- worry\n",
            "@mr_trick It's all good  The next 6 months are going to be awesome. <---- happiness\n",
            "Apparently its Star Wars Day today - so May the 4th be with you  http://tinyurl.com/axsujx <---- happiness\n",
            "Rest In Peace  ADaM 12 &amp; GLeNN EPPS.... Gone but never forgotten... what a week ...Loud in da air 4 ya <---- love\n",
            "I miss my puppy <---- worry\n",
            "Morning and hope everyone has a great bank holiday <---- happiness\n",
            "Just finished my 1st new song !!!  Soon on Youtube !  Keeping you updated ! <---- happiness\n",
            "Just shot my new .22 rifle!  The auto-reset plinker target I built in shop class works great! <---- happiness\n",
            "Exams are kinda near. Just a week more. 2 Projects yet to be submitted  and almost failing in one of the subjects. May ALLAH save me <---- worry\n",
            "I can't open my eyes properly, maybe if i sleep for a lil' while longer it'll fix itself <---- worry\n",
            "@tylerakira - ughhh!!! have to go back there tonight <---- worry\n",
            "@GoodGreenTea Its been a fun afternoon for me trying though....BBQ's out now though...feeling a bit sick <---- worry\n",
            "i just made the best turtle ice cream pie everrrrr  btw, happy (soon to be) mothers day! <---- love\n",
            "Just FYI, RUIN HOLLYWOOD IS CLOSED.  Last Friday was our Closing Night. <---- worry\n",
            "Back to the freaking homework. <---- hate\n",
            "@Corrina2008 your bitches miss you!!!! <---- sadness\n",
            "Good Morning Twitts! Another GloOmy day in NYC! <---- neutral\n",
            "@tncc24 - so sweet  why aren't you out livin' it up this saturday night? <---- love\n",
            "@1critic Yep, ah, damn, I don't wanna leave my warm doona to get a hot beverage...I guess I'll just have to make do w/o it <---- worry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZK8td4txj1Z",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2eSnUkjxnEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch):\n",
        "    return 3e-5 * 0.2**epoch\n",
        "\n",
        "def build_model():\n",
        "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "\n",
        "    config = RobertaConfig.from_pretrained(ROBERTA_PATH + 'config-roberta-base.json')\n",
        "    bert_model = TFRobertaModel.from_pretrained(CHECKPOINT_PATH + 'finetuned_roberta_pretrained/')\n",
        "    # bert_model = TFRobertaModel.from_pretrained(ROBERTA_PATH + 'pretrained-roberta-base.h5',config=config)\n",
        "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
        "    \n",
        "    \n",
        "    x1 = tf.keras.layers.Dropout(0.3)(x[0]) \n",
        "    x1 = tf.keras.layers.Conv1D(128, 2,padding='same')(x1)\n",
        "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
        "    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n",
        "    x1 = tf.keras.layers.Dense(1)(x1)\n",
        "    x1 = tf.keras.layers.Flatten()(x1)\n",
        "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
        "    \n",
        "    x2 = tf.keras.layers.Dropout(0.3)(x[0]) \n",
        "    x2 = tf.keras.layers.Conv1D(128, 2, padding='same')(x2)\n",
        "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
        "    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n",
        "    x2 = tf.keras.layers.Dense(1)(x2)\n",
        "    x2 = tf.keras.layers.Flatten()(x2)\n",
        "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49tvlLy6mRsf",
        "colab_type": "code",
        "outputId": "ef9edb79-4702-4f66-e383-b4a9cd1d73eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 120)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 120)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 120)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode ((None, 120, 768), ( 124645632   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 120, 768)     0           tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 120, 768)     0           tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 120, 128)     196736      dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 120, 128)     196736      dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 120, 128)     0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 120, 128)     0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 120, 64)      16448       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 120, 64)      16448       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 120, 1)       65          conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 120, 1)       65          conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 120)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 120)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 120)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 120)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 125,072,130\n",
            "Trainable params: 125,072,130\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iyatZy1xo2f",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jdpn1mOxoHl",
        "colab_type": "code",
        "outputId": "4d2c7a07-14d0-493d-edbd-c1c2d1414c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "n_splits = 5\n",
        "\n",
        "\n",
        "jac = []\n",
        "oof_start = np.zeros((input_ids.shape[0],MAX_LEN))\n",
        "oof_end = np.zeros((input_ids.shape[0],MAX_LEN))\n",
        "\n",
        "skf = StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=777)\n",
        "for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train_df.sentiment.values)):\n",
        "\n",
        "    print_to_file('#'*25)\n",
        "    print_to_file('### FOLD %i'%(fold+1))\n",
        "    print_to_file('#'*25)\n",
        "    \n",
        "    K.clear_session()\n",
        "    model = build_model()\n",
        "    if not os.path.exists(CHECKPOINT_PATH + '%s-roberta-%i.h5'%(VER,fold)):\n",
        "          \n",
        "      reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "      sv = tf.keras.callbacks.ModelCheckpoint(\n",
        "          CHECKPOINT_PATH + '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n",
        "          save_weights_only=True, mode='auto', save_freq='epoch')\n",
        "          \n",
        "      X = [input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]]\n",
        "      Y = [start_tokens[idxT,], end_tokens[idxT,]]\n",
        "      X_valid = [input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]]\n",
        "      Y_valid = [start_tokens[idxV,], end_tokens[idxV,]]\n",
        "      hist = model.fit(\n",
        "          X,\n",
        "          Y,\n",
        "          epochs=3,\n",
        "          batch_size=8,\n",
        "          verbose=DISPLAY,\n",
        "          callbacks=[sv, reduce_lr],\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "          )\n",
        "    else:\n",
        "      print_to_file(\"training Fold %d is skipped!\"%(fold+1))\n",
        "\n",
        "    print_to_file('Loading model...')\n",
        "    model.load_weights(CHECKPOINT_PATH + '%s-roberta-%i.h5'%(VER,fold))\n",
        "    \n",
        "    print_to_file('Predicting OOF...')\n",
        "    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n",
        "    \n",
        "    # DISPLAY FOLD JACCARD\n",
        "    all = []\n",
        "    for k in idxV:\n",
        "        a = np.argmax(oof_start[k,])\n",
        "        b = np.argmax(oof_end[k,])\n",
        "\n",
        "        if (a>b) and MAX_MULT_PROB and train_df.loc[k,'sentiment'] != \"neutral\": \n",
        "          context_len = oof_end.shape[1]\n",
        "          maxprod = 0\n",
        "          chosen_start = 0\n",
        "          chosen_end = 0\n",
        "          for i in range(context_len):\n",
        "              end_dist_subset = oof_end[k,i:]\n",
        "              end_prob_max = np.amax(end_dist_subset)\n",
        "              end_idx = np.argmax(end_dist_subset)\n",
        "              start_prob = oof_start[k,i]\n",
        "              prod = end_prob_max*start_prob\n",
        "              if prod > maxprod:\n",
        "                  maxprod = prod\n",
        "                  chosen_start = i\n",
        "                  chosen_end = chosen_start+end_idx\n",
        "\n",
        "          a = chosen_start\n",
        "          b = chosen_end\n",
        "\n",
        "        if (a>b):\n",
        "          st = train_df.loc[k,'text'] \n",
        "        else:\n",
        "          text1 = \" \"+\" \".join(train_df.loc[k,'text'].split())\n",
        "          enc = tokenizer.encode(text1)\n",
        "          st = tokenizer.decode(enc.ids[a-1:b])\n",
        "        \n",
        "        train_df.loc[k,'selected_text_predicted'] = st\n",
        "        train_df.loc[k,'jaccard'] = jaccard(train_df.loc[k,'selected_text_predicted'],train_df.loc[k,'selected_text'])\n",
        "        if train_df.loc[k,'source'] == \"competition\":\n",
        "          all.append(train_df.loc[k,'jaccard'])\n",
        "\n",
        "    jac.append(np.mean(all))\n",
        "    print_to_file('>>>> FOLD %i Jaccard = '%(fold+1) + str(np.mean(all)))\n",
        "    print()\n",
        "\n",
        "\n",
        "print_to_file('Overall averrage of Jaccards = ' + str(np.mean(jac)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#########################\n",
            "### FOLD 1\n",
            "#########################\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "2748/2748 [==============================] - ETA: 0s - loss: 0.0266 - activation_loss: 0.0134 - activation_1_loss: 0.0132\n",
            "Epoch 00001: val_loss improved from inf to 0.02351, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/v7-roberta-0.h5\n",
            "2748/2748 [==============================] - 416s 151ms/step - loss: 0.0266 - activation_loss: 0.0134 - activation_1_loss: 0.0132 - val_loss: 0.0235 - val_activation_loss: 0.0118 - val_activation_1_loss: 0.0117 - lr: 3.0000e-05\n",
            "Epoch 2/3\n",
            "2748/2748 [==============================] - ETA: 0s - loss: 0.0208 - activation_loss: 0.0106 - activation_1_loss: 0.0102\n",
            "Epoch 00002: val_loss improved from 0.02351 to 0.02191, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/v7-roberta-0.h5\n",
            "2748/2748 [==============================] - 419s 152ms/step - loss: 0.0208 - activation_loss: 0.0106 - activation_1_loss: 0.0102 - val_loss: 0.0219 - val_activation_loss: 0.0112 - val_activation_1_loss: 0.0107 - lr: 6.0000e-06\n",
            "Epoch 3/3\n",
            "2748/2748 [==============================] - ETA: 0s - loss: 0.0194 - activation_loss: 0.0099 - activation_1_loss: 0.0095\n",
            "Epoch 00003: val_loss did not improve from 0.02191\n",
            "2748/2748 [==============================] - 416s 151ms/step - loss: 0.0194 - activation_loss: 0.0099 - activation_1_loss: 0.0095 - val_loss: 0.0222 - val_activation_loss: 0.0113 - val_activation_1_loss: 0.0108 - lr: 1.2000e-06\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "172/172 [==============================] - 28s 165ms/step\n",
            ">>>> FOLD 1 Jaccard = 0.7042981369438003\n",
            "\n",
            "#########################\n",
            "### FOLD 2\n",
            "#########################\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            " 243/2749 [=>............................] - ETA: 6:27 - loss: 0.0466 - activation_loss: 0.0230 - activation_1_loss: 0.0236"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btMpOh5St6by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########################\n",
        "### FOLD 1\n",
        "#########################\n",
        "Epoch 1/3\n",
        "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
        "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
        "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
        "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
        "2748/2748 [==============================] - ETA: 0s - loss: 0.0325 - activation_loss: 0.0165 - activation_1_loss: 0.0160\n",
        "Epoch 00001: val_loss improved from inf to 0.02835, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/v6-roberta-0.h5\n",
        "2748/2748 [==============================] - 351s 128ms/step - loss: 0.0325 - activation_loss: 0.0165 - activation_1_loss: 0.0160 - val_loss: 0.0283 - val_activation_loss: 0.0145 - val_activation_1_loss: 0.0138 - lr: 3.0000e-05\n",
        "Epoch 2/3\n",
        "2748/2748 [==============================] - ETA: 0s - loss: 0.0256 - activation_loss: 0.0131 - activation_1_loss: 0.0125\n",
        "Epoch 00002: val_loss improved from 0.02835 to 0.02735, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/v6-roberta-0.h5\n",
        "2748/2748 [==============================] - 349s 127ms/step - loss: 0.0256 - activation_loss: 0.0131 - activation_1_loss: 0.0125 - val_loss: 0.0273 - val_activation_loss: 0.0140 - val_activation_1_loss: 0.0134 - lr: 6.0000e-06\n",
        "Epoch 3/3\n",
        "2748/2748 [==============================] - ETA: 0s - loss: 0.0240 - activation_loss: 0.0122 - activation_1_loss: 0.0117\n",
        "Epoch 00003: val_loss did not improve from 0.02735\n",
        "2748/2748 [==============================] - 342s 125ms/step - loss: 0.0240 - activation_loss: 0.0122 - activation_1_loss: 0.0117 - val_loss: 0.0275 - val_activation_loss: 0.0140 - val_activation_1_loss: 0.0136 - lr: 1.2000e-06\n",
        "Loading model...\n",
        "Predicting OOF...\n",
        "172/172 [==============================] - 23s 135ms/step\n",
        ">>>> FOLD 1 Jaccard = 0.7045174031165262\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbA6K8ldxyUc",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pho4ql-hxxYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
        "preds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
        "DISPLAY=1\n",
        "for i in range(5):\n",
        "    print_to_file('#'*25)\n",
        "    print_to_file('### MODEL %i'%(i+1))\n",
        "    print_to_file('#'*25)\n",
        "    \n",
        "    K.clear_session()\n",
        "    model = build_model()\n",
        "    model.load_weights(CHECKPOINT_PATH + '%s-roberta-%i.h5'%(VER,i))\n",
        "\n",
        "    print_to_file('Predicting Test...')\n",
        "    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
        "    preds_start += preds[0]/n_splits\n",
        "    preds_end += preds[1]/n_splits\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p31hQI95x4Ra",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RQkmXq4x3Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all = []\n",
        "for k in range(input_ids_t.shape[0]):\n",
        "    a = np.argmax(preds_start[k,])\n",
        "    b = np.argmax(preds_end[k,])\n",
        "\n",
        "    if (a>b) and MAX_MULT_PROB and test_df.loc[k,'sentiment'] != \"neutral\" : \n",
        "      context_len = preds_end.shape[1]\n",
        "      maxprod = 0\n",
        "      chosen_start = 0\n",
        "      chosen_end = 0\n",
        "      for i in range(context_len):\n",
        "          end_dist_subset = preds_end[k,i:]\n",
        "          end_prob_max = np.amax(end_dist_subset)\n",
        "          end_idx = np.argmax(end_dist_subset)\n",
        "          start_prob = preds_start[k,i]\n",
        "          prod = end_prob_max*start_prob\n",
        "          if prod > maxprod:\n",
        "              maxprod = prod\n",
        "              chosen_start = i\n",
        "              chosen_end = chosen_start+end_idx\n",
        "\n",
        "      a = chosen_start\n",
        "      b = chosen_end\n",
        "\n",
        "    if (a>b): \n",
        "        st = test_df.loc[k,'text']\n",
        "    else:\n",
        "        text1 = \" \"+\" \".join(test_df.loc[k,'text'].split())\n",
        "        enc = tokenizer.encode(text1)\n",
        "        st = tokenizer.decode(enc.ids[a-1:b])\n",
        "    all.append(st)\n",
        "\n",
        "test_df['selected_text'] = all\n",
        "test_df['selected_text'] = test_df['selected_text'].apply(add_html)\n",
        "\n",
        "test_df['selected_text'] = test_df['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\n",
        "test_df['selected_text'] = test_df['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\n",
        "test_df['selected_text'] = test_df['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n",
        "\n",
        "test_df[['textID','selected_text']].to_csv('submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}