{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_roberta_tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1V7tFsyBcTwoJvCOCL4Q8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/branjbar/nlp-bert-family/blob/master/tensorflow/tensorflow_roberta_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y31um2QhaaUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/rftexas/roberta-with-tensorflow-on-tpu/comments"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZGGy9xat9YB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "017c6f28-29a3-4377-ce98-5db8b5e3a6ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSQuuYy7t95n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "6bf25a23-f2b2-4ffd-fb4f-2a5b9475cfd0"
      },
      "source": [
        "!pip install transformers\n",
        "import os\n",
        "import pandas as pd, numpy as np\n",
        "import time, re, math\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import *\n",
        "import tokenizers\n",
        "import random\n",
        "print('TF version',tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
            "TF version 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U70KuuAbuIYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "201063d0-4b11-4177-f566-2456c6260ab3"
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError: # If TPU not found\n",
        "  tpu = None\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    # This is the TPU initialization code that has to be at the beginning.\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() # Default strategy that works on CPU and single GPU\n",
        "    print('Running on CPU instead')\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.126.170.130:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.126.170.130:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.126.170.130:8470']\n",
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D3cD48LelY0",
        "colab_type": "text"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWy8WQqtuBE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KAGGLE_INPUT_PATH = \"../input/\"\n",
        "COLAB_INPUT_PATH = \"/content/drive/My Drive/input/\"\n",
        "INPUT_PATH = COLAB_INPUT_PATH\n",
        "\n",
        "DATA_PATH = INPUT_PATH + \"tweet-sentiment-extraction/\"\n",
        "CHECKPOINT_PATH = INPUT_PATH + \"model_checkpoint/roberta/\"\n",
        "ROBERTA_PATH = INPUT_PATH + 'tf-roberta/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPa9W-ocewcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
        "    vocab_file= ROBERTA_PATH +'vocab-roberta-base.json', \n",
        "    merges_file= ROBERTA_PATH +'merges-roberta-base.txt', \n",
        "    lowercase=True,\n",
        "    add_prefix_space=True\n",
        ")\n",
        "SENTIMENT_ID = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpYqp0mIeo4s",
        "colab_type": "text"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iTERuGfe6fJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    def __init__(self, config_path=None):\n",
        "\n",
        "        if config_path:\n",
        "            with open(config_path,'r') as json_file:\n",
        "                self.__dict__ = json.load(json_file)\n",
        "        else:\n",
        "            \n",
        "            self.version='tf-tpu-v1'\n",
        "\n",
        "            # preprocessing\n",
        "            self.max_len = 120\n",
        "            # self.tweet_size_to_ignore = 1\n",
        "\n",
        "            # learning\n",
        "            self.drop_out = 0.3\n",
        "            self.conv1d_size_1 = 128\n",
        "            self.conv1d_size_2 = 64\n",
        "            self.lr = 3e-5\n",
        "            self.lr_decrease = 0.2\n",
        "            self.label_smoothing = 0.25\n",
        "            self.train_batch_size = 8\n",
        "            self.valid_batch_size = 16\n",
        "            self.num_epochs = 3\n",
        "            self.num_folds = 5\n",
        "            self.smart_span = True\n",
        "            # dev\n",
        "            self.num_folds_to_train = 1\n",
        "            self.dev = False\n",
        "            self.overwrite_model = True\n",
        "        \n",
        "        # print(str(self.__dict__))\n",
        "\n",
        "    def get(self, var):\n",
        "        return getattr(self, var, None)\n",
        "\n",
        "\n",
        "# config_file_name = \"config-json-tpu-v28.txt\"\n",
        "# config_file_path = os.path.join(CHECKPOINT_PATH_HP_TUNING,config_file_name)\n",
        "# if os.path.exists(config_file_path):\n",
        "    # config = Config(config_file_path)\n",
        "# else:\n",
        "    # print(\"config file not found! Default configuration will be used\")\n",
        "config = Config()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6neYZwqEeq9T",
        "colab_type": "text"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ks9Sj0CuHWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_to_file(config, text):\n",
        "  try:\n",
        "    f = open(CHECKPOINT_PATH + config.version + \"_logs.txt\", 'a')\n",
        "  except:\n",
        "    f = open(CHECKPOINT_PATH + config.version + \"_logs.txt\", 'w')\n",
        "\n",
        "  print(text)\n",
        "  f.write(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  f.write(\"  -- \")\n",
        "  f.write(text)\n",
        "  f.write(\"\\n\")\n",
        "\n",
        "def jaccard(str1, str2): \n",
        "\n",
        "    a = set(str(str1).lower().split()) \n",
        "    b = set(str(str2).lower().split())\n",
        "\n",
        "    c = a.intersection(b)\n",
        "\n",
        "    if (len(a) + len(b) - len(c)) > 0:\n",
        "      return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIgKJIhegxRV",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaj2JglXuVhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_data(config):\n",
        "    def read_train():\n",
        "        train=pd.read_csv(DATA_PATH + 'train.csv')\n",
        "        train['text']=train['text'].astype(str)\n",
        "        train['selected_text']=train['selected_text'].astype(str)\n",
        "\n",
        "        return train\n",
        "\n",
        "    def read_test():\n",
        "        test=pd.read_csv(DATA_PATH + 'test.csv')\n",
        "        test['text']=test['text'].astype(str)\n",
        "\n",
        "        return test\n",
        "\n",
        "    if (config.dev == True):\n",
        "        train_df = read_train().sample(frac=.05, random_state=1).reset_index()\n",
        "        test_df = read_test().sample(frac=.05, random_state=1).reset_index()\n",
        "    else:\n",
        "        train_df = read_train()\n",
        "        test_df = read_test()\n",
        "\n",
        "\n",
        "    print_to_file(config, \"train_df shape:\" + str(train_df.shape))\n",
        "    print_to_file(config, \"test_df shape:\" + str(test_df.shape))\n",
        "    \n",
        "    return train_df, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOZTcNnZhICe",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOXSqpFxuXGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_train(config, train_df):\n",
        "    ct = train_df.shape[0]\n",
        "    input_ids = np.ones((ct,config.max_len),dtype='int32')\n",
        "    attention_mask = np.zeros((ct,config.max_len),dtype='int32')\n",
        "    token_type_ids = np.zeros((ct,config.max_len),dtype='int32')\n",
        "    start_tokens = np.zeros((ct,config.max_len),dtype='int32')\n",
        "    end_tokens = np.zeros((ct,config.max_len),dtype='int32')\n",
        "\n",
        "    for k in range(train_df.shape[0]):\n",
        "        \n",
        "        # FIND OVERLAP\n",
        "        text1 = \" \"+\" \".join(train_df.loc[k,'text'].split())\n",
        "        text2 = \" \".join(train_df.loc[k,'selected_text'].split())\n",
        "        idx = text1.find(text2)\n",
        "        chars = np.zeros((len(text1)))\n",
        "        chars[idx:idx+len(text2)]=1\n",
        "        if text1[idx-1]==' ': chars[idx-1] = 1 \n",
        "        enc = tokenizer.encode(text1) \n",
        "            \n",
        "        # ID_OFFSETS\n",
        "        offsets = []; idx=0\n",
        "        for t in enc.ids:\n",
        "            w = tokenizer.decode([t])\n",
        "            offsets.append((idx,idx+len(w)))\n",
        "            idx += len(w)\n",
        "        \n",
        "        # START END TOKENS\n",
        "        toks = []\n",
        "        for i,(a,b) in enumerate(offsets):\n",
        "            sm = np.sum(chars[a:b])\n",
        "            if sm>0: toks.append(i) \n",
        "            \n",
        "        s_tok = SENTIMENT_ID[train_df.loc[k,'sentiment']]\n",
        "        input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
        "        attention_mask[k,:len(enc.ids)+5] = 1\n",
        "        if len(toks)>0:\n",
        "            start_tokens[k,toks[0]+1] = 1\n",
        "            end_tokens[k,toks[-1]+1] = 1\n",
        "    return  input_ids, attention_mask, token_type_ids, start_tokens, end_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA_vXWpuucFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_dataset(config, idxT, idxV, input_ids, attention_mask, token_type_ids, start_tokens, end_tokens):\n",
        "    \n",
        "    # Trainset\n",
        "    trn_input_ids = input_ids[idxT,]\n",
        "    trn_att_mask = attention_mask[idxT,]\n",
        "    trn_token_type_ids = token_type_ids[idxT,]\n",
        "    \n",
        "    trn_start_tokens = start_tokens[idxT,]\n",
        "    trn_end_tokens = end_tokens[idxT,]\n",
        "    \n",
        "    # Validation set\n",
        "    val_input_ids = input_ids[idxV,]\n",
        "    val_att_mask = attention_mask[idxV,]\n",
        "    val_token_type_ids = token_type_ids[idxV,]\n",
        "    \n",
        "    val_start_tokens = start_tokens[idxV,]\n",
        "    val_end_tokens = end_tokens[idxV,]\n",
        "    \n",
        "    # Generating tf.data object\n",
        "    train_dataset = (\n",
        "        tf.data.Dataset\n",
        "        .from_tensor_slices(({'input_ids':trn_input_ids, 'attention_mask': trn_att_mask, 'token_type_ids': trn_token_type_ids}, \n",
        "                             {'start_tokens': trn_start_tokens, 'end_tokens': trn_end_tokens}))\n",
        "        .shuffle(2048)\n",
        "        .batch(config.train_batch_size)\n",
        "        .prefetch(AUTO)\n",
        "    )\n",
        "    \n",
        "    valid_dataset = (\n",
        "        tf.data.Dataset\n",
        "        .from_tensor_slices(({'input_ids':val_input_ids, 'attention_mask': val_att_mask, 'token_type_ids': val_token_type_ids}, \n",
        "                             {'start_tokens': val_start_tokens, 'end_tokens': val_end_tokens}))\n",
        "        .batch(config.valid_batch_size)\n",
        "        .cache()\n",
        "        .prefetch(AUTO)\n",
        "    )\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvUiECrcjbh6",
        "colab_type": "text"
      },
      "source": [
        "# Design Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t37zAgJTueNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch):\n",
        "    return config.lr * config.lr_decrease**epoch\n",
        "\n",
        "def build_model(config):\n",
        "    ids = tf.keras.layers.Input((config.max_len,), dtype=tf.int32, name='input_ids')\n",
        "    att = tf.keras.layers.Input((config.max_len,), dtype=tf.int32, name='attention_mask')\n",
        "    tok = tf.keras.layers.Input((config.max_len,), dtype=tf.int32, name='token_type_ids')\n",
        "\n",
        "    robert_config = RobertaConfig.from_pretrained(ROBERTA_PATH + 'config-roberta-base.json')\n",
        "    bert_model = TFRobertaModel.from_pretrained(ROBERTA_PATH + 'pretrained-roberta-base.h5',config=robert_config)\n",
        "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
        "    \n",
        "    \n",
        "    x1 = tf.keras.layers.Dropout(config.drop_out)(x[0]) \n",
        "    x1 = tf.keras.layers.Conv1D(config.conv1d_size_1, 2, padding='same')(x1)\n",
        "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
        "    x1 = tf.keras.layers.Conv1D(config.conv1d_size_2, 2, padding='same')(x1)\n",
        "    x1 = tf.keras.layers.Dense(1)(x1)\n",
        "    x1 = tf.keras.layers.Flatten()(x1)\n",
        "    x1 = tf.keras.layers.Activation('softmax', name='start_tokens')(x1)\n",
        "    \n",
        "    x2 = tf.keras.layers.Dropout(config.drop_out)(x[0]) \n",
        "    x2 = tf.keras.layers.Conv1D(config.conv1d_size_1, 2, padding='same')(x2)\n",
        "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
        "    x2 = tf.keras.layers.Conv1D(config.conv1d_size_2, 2, padding='same')(x2)\n",
        "    x2 = tf.keras.layers.Dense(1)(x2)\n",
        "    x2 = tf.keras.layers.Flatten()(x2)\n",
        "    x2 = tf.keras.layers.Activation('softmax', name='end_tokens')(x2)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ex5nAdzjdtb",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KlUcgkbjgcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_train(config, train_df, input_ids, attention_mask, token_type_ids, start_tokens, end_tokens):\n",
        "    print_to_file(config, str(config.__dict__))\n",
        "    jac = []\n",
        "    oof_start = np.zeros((input_ids.shape[0],config.max_len))\n",
        "    oof_end = np.zeros((input_ids.shape[0],config.max_len))\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=config.num_folds, shuffle=True, random_state=777)\n",
        "    for fold, (idxT,idxV) in enumerate(skf.split(input_ids, train_df.sentiment.values)):\n",
        "        if fold < config.num_folds_to_train:\n",
        "            print_to_file(config, '#'*25)\n",
        "            print_to_file(config, '### FOLD %i'%(fold+1))\n",
        "            print_to_file(config, '#'*25)\n",
        "\n",
        "            trn_dataset, val_dataset = generate_dataset(config, idxT, idxV, input_ids, attention_mask, token_type_ids, start_tokens, end_tokens)\n",
        "\n",
        "            if config.overwrite_model or (not os.path.exists(CHECKPOINT_PATH + '%s-roberta-%i.h5'%(config.version,fold))):\n",
        "                K.clear_session()\n",
        "                with strategy.scope():\n",
        "                    model = build_model(config)\n",
        "                    model.compile(\n",
        "                        optimizer = tf.keras.optimizers.Adam(learning_rate=config.lr),\n",
        "                        loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=config.label_smoothing)\n",
        "                        )\n",
        "            \n",
        "                reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda epoch: config.lr * config.lr_decrease**epoch, verbose=1)\n",
        "\n",
        "                sv = tf.keras.callbacks.ModelCheckpoint(\n",
        "                    CHECKPOINT_PATH + '%s-roberta-%i.h5'%(config.version,fold), monitor='val_loss', verbose=1, save_best_only=True,\n",
        "                    save_weights_only=True, mode='auto', save_freq='epoch')\n",
        "                hist = model.fit(\n",
        "                    trn_dataset,\n",
        "                    epochs=config.num_epochs,\n",
        "                    batch_size=config.train_batch_size,\n",
        "                    verbose=1,\n",
        "                    callbacks=[sv, reduce_lr],\n",
        "                    validation_data=val_dataset\n",
        "                    )\n",
        "            else:\n",
        "                print_to_file(config, \"training Fold %d is skipped!\"%(fold+1))\n",
        "\n",
        "            print_to_file(config, 'Loading model...')\n",
        "            model.load_weights(CHECKPOINT_PATH + '%s-roberta-%i.h5'%(config.version,fold))\n",
        "            \n",
        "            print_to_file(config, 'Predicting OOF...')\n",
        "            oof_start[idxV,],oof_end[idxV,] = model.predict(val_dataset, verbose=1)\n",
        "            \n",
        "            # DISPLAY FOLD JACCARD\n",
        "            all = []\n",
        "            for k in idxV:\n",
        "                a = np.argmax(oof_start[k,])\n",
        "                b = np.argmax(oof_end[k,])\n",
        "\n",
        "                if (a>b) and config.smart_span: \n",
        "                    max_len = len(oof_start[k,])\n",
        "                    a = np.tile(oof_start[k,], (max_len, 1))\n",
        "                    b = np.tile(oof_end[k,], (max_len, 1))\n",
        "                    c = np.tril(a + b.T, k=0).T\n",
        "                    c[c == 0] = -1000\n",
        "                    a = np.unravel_index(c.argmax(), c.shape)[0]\n",
        "                    b = np.unravel_index(c.argmax(), c.shape)[1]\n",
        "\n",
        "                if (a>b):\n",
        "                    st = train_df.loc[k,'text'] \n",
        "                else:\n",
        "                    text1 = \" \"+\" \".join(train_df.loc[k,'text'].split())\n",
        "                    enc = tokenizer.encode(text1)\n",
        "                    st = tokenizer.decode(enc.ids[a-1:b])\n",
        "                \n",
        "                train_df.loc[k,'selected_text_predicted'] = st\n",
        "                train_df.loc[k,'jaccard'] = jaccard(train_df.loc[k,'selected_text_predicted'],train_df.loc[k,'selected_text'])\n",
        "                all.append(train_df.loc[k,'jaccard'])\n",
        "\n",
        "            jac.append(np.mean(all))\n",
        "            print_to_file(config, '>>>> FOLD %i Jaccard = '%(fold+1) + str(np.mean(all)))\n",
        "\n",
        "    K.clear_session()\n",
        "    print_to_file(config, 'Overall averrage of Jaccards in %i folds = '% (fold+1) + str(np.mean(jac)))\n",
        "    return np.mean(jac)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NQoD78n_YyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def have_intersection(d1,d2):\n",
        "    flag_intersect_total = False\n",
        "    for i in range(d2.shape[0]):\n",
        "        flag_interset_row = True\n",
        "        for c in d1.columns:\n",
        "            if (c != \"version\") and (c!= \"score\"):\n",
        "                a = d1.iloc[0][c]\n",
        "                b = d2.iloc[i][c]\n",
        "                if type(a) == np.float64:\n",
        "                    if not np.round(a,decimals=10) == np.round(b,decimals=10):\n",
        "                        flag_interset_row = False\n",
        "                else:\n",
        "                    if not a == b:\n",
        "                        flag_interset_row = False\n",
        "        if flag_interset_row:\n",
        "            flag_intersect_total = True\n",
        "    flag_intersect_total\n",
        "    return flag_intersect_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dev0RlUWf4PY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f026c781-f87a-4e8c-c345-d993e3f66e8d"
      },
      "source": [
        "list_lr = [5e-6, 1e-5, 2e-5, 3e-5, 6e-5, 9e-5]\n",
        "list_lr_decrease = [.1, .2, .5, .7]\n",
        "list_dropout = [0, .1, .2, .3, .4, .5]\n",
        "list_conv1d_size_1 = [64, 128, 256, 512]\n",
        "list_conv1d_size_2 = [8, 16, 32, 64]\n",
        "list_label_smoothing = [0, .05, .1, .15, .2, .25, .3, .35, .4, .45, .5]\n",
        "list_num_epochs = [3,4,5]\n",
        "\n",
        "session_num = 0\n",
        "random.seed(67876)\n",
        "for i in range(100):\n",
        "    K.clear_session()\n",
        "    config = Config()\n",
        "    config.dev = False\n",
        "    config.num_folds_to_train = 2\n",
        "    config.overwrite_model = True\n",
        "    config.train_batch_size = 8\n",
        "    config.valid_batch_size = 16\n",
        "    config.num_folds = 5\n",
        "    config.smart_span = True\n",
        "\n",
        "    config.lr = random.choice(list_lr)\n",
        "    config.lr_decrease = random.choice(list_lr_decrease)\n",
        "    config.drop_out = random.choice(list_dropout)\n",
        "    config.conv1d_size_1 = random.choice(list_conv1d_size_1)\n",
        "    config.conv1d_size_2 = random.choice(list_conv1d_size_2)\n",
        "    config.label_smoothing = random.choice(list_label_smoothing)\n",
        "    config.num_epochs = random.choice(list_num_epochs)\n",
        "    config.version = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    run_name = \"run-%d\" % session_num\n",
        "    df = pd.DataFrame(config.__dict__, index=[0])\n",
        "    flag_continue = True\n",
        "    df_hist = pd.DataFrame()\n",
        "    if os.path.exists(CHECKPOINT_PATH + \"tensorboard/config_logs.csv\"):\n",
        "        df_hist = pd.read_csv(CHECKPOINT_PATH + \"tensorboard/config_logs.csv\")\n",
        "        if have_intersection(df,df_hist):\n",
        "            print(\"this setting already exists!\")\n",
        "            flag_continue = False\n",
        "\n",
        "    else:\n",
        "        print(\"no history exists\")\n",
        "\n",
        "    if flag_continue:\n",
        "        print(\"session:\", session_num)\n",
        "        print(df.iloc[0])\n",
        "        \n",
        "        train_df, test_df = import_data(config)\n",
        "        input_ids, attention_mask, token_type_ids, start_tokens, end_tokens = preprocess_train(config, train_df)\n",
        "        score = run_train(config, train_df, input_ids, attention_mask, token_type_ids, start_tokens, end_tokens)\n",
        "        df[\"score\"] = score\n",
        "\n",
        "        if df_hist.shape[0] > 0:\n",
        "            df_full = pd.concat([df_hist, df])\n",
        "        else: \n",
        "            df_full = df\n",
        "        \n",
        "        df_full.to_csv(CHECKPOINT_PATH + \"tensorboard/config_logs.csv\", index=False)\n",
        "        print(\"Final Score for VER %s is: %.5f\" % (config.version, score))\n",
        "        print(df_full.iloc[-1])\n",
        "        session_num += 1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "this setting already exists!\n",
            "session: 0\n",
            "version               20200505-094811\n",
            "max_len                           120\n",
            "drop_out                          0.5\n",
            "conv1d_size_1                     512\n",
            "conv1d_size_2                      64\n",
            "lr                              5e-06\n",
            "lr_decrease                       0.2\n",
            "label_smoothing                   0.1\n",
            "train_batch_size                    8\n",
            "valid_batch_size                   16\n",
            "num_epochs                          3\n",
            "num_folds                           5\n",
            "smart_span                       True\n",
            "num_folds_to_train                  2\n",
            "dev                             False\n",
            "overwrite_model                  True\n",
            "Name: 0, dtype: object\n",
            "train_df shape:(27481, 4)\n",
            "test_df shape:(3534, 3)\n",
            "{'version': '20200505-094811', 'max_len': 120, 'drop_out': 0.5, 'conv1d_size_1': 512, 'conv1d_size_2': 64, 'lr': 5e-06, 'lr_decrease': 0.2, 'label_smoothing': 0.1, 'train_batch_size': 8, 'valid_batch_size': 16, 'num_epochs': 3, 'num_folds': 5, 'smart_span': True, 'num_folds_to_train': 2, 'dev': False, 'overwrite_model': True}\n",
            "#########################\n",
            "### FOLD 1\n",
            "#########################\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 5e-06.\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2748/2748 [==============================] - ETA: 0s - start_tokens_loss: 0.2742 - loss: 0.5481 - end_tokens_loss: 0.2740\n",
            "Epoch 00001: val_loss improved from inf to 0.54285, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/20200505-094811-roberta-0.h5\n",
            "2748/2748 [==============================] - 267s 97ms/step - start_tokens_loss: 0.2742 - loss: 0.5481 - end_tokens_loss: 0.2740 - val_start_tokens_loss: 0.2715 - val_loss: 0.5428 - val_end_tokens_loss: 0.2713 - lr: 5.0000e-06\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
            "Epoch 2/3\n",
            "2748/2748 [==============================] - ETA: 0s - start_tokens_loss: 0.2720 - loss: 0.5439 - end_tokens_loss: 0.2719\n",
            "Epoch 00002: val_loss improved from 0.54285 to 0.54256, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/20200505-094811-roberta-0.h5\n",
            "2748/2748 [==============================] - 269s 98ms/step - start_tokens_loss: 0.2720 - loss: 0.5439 - end_tokens_loss: 0.2719 - val_start_tokens_loss: 0.2713 - val_loss: 0.5426 - val_end_tokens_loss: 0.2712 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 2.0000000000000004e-07.\n",
            "Epoch 3/3\n",
            "2748/2748 [==============================] - ETA: 0s - start_tokens_loss: 0.2718 - loss: 0.5436 - end_tokens_loss: 0.2718\n",
            "Epoch 00003: val_loss improved from 0.54256 to 0.54248, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/20200505-094811-roberta-0.h5\n",
            "2748/2748 [==============================] - 265s 96ms/step - start_tokens_loss: 0.2718 - loss: 0.5436 - end_tokens_loss: 0.2718 - val_start_tokens_loss: 0.2713 - val_loss: 0.5425 - val_end_tokens_loss: 0.2712 - lr: 2.0000e-07\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "344/344 [==============================] - 9s 27ms/step\n",
            ">>>> FOLD 1 Jaccard = 0.6968698104038509\n",
            "#########################\n",
            "### FOLD 2\n",
            "#########################\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 5e-06.\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2749/2749 [==============================] - ETA: 0s - start_tokens_loss: 0.2741 - loss: 0.5479 - end_tokens_loss: 0.2738\n",
            "Epoch 00001: val_loss improved from inf to 0.54307, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/20200505-094811-roberta-1.h5\n",
            "2749/2749 [==============================] - 267s 97ms/step - start_tokens_loss: 0.2741 - loss: 0.5479 - end_tokens_loss: 0.2738 - val_start_tokens_loss: 0.2716 - val_loss: 0.5431 - val_end_tokens_loss: 0.2715 - lr: 5.0000e-06\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
            "Epoch 2/3\n",
            "2749/2749 [==============================] - ETA: 0s - start_tokens_loss: 0.2718 - loss: 0.5435 - end_tokens_loss: 0.2717\n",
            "Epoch 00002: val_loss improved from 0.54307 to 0.54287, saving model to /content/drive/My Drive/input/model_checkpoint/roberta/20200505-094811-roberta-1.h5\n",
            "2749/2749 [==============================] - 267s 97ms/step - start_tokens_loss: 0.2718 - loss: 0.5435 - end_tokens_loss: 0.2717 - val_start_tokens_loss: 0.2715 - val_loss: 0.5429 - val_end_tokens_loss: 0.2714 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 2.0000000000000004e-07.\n",
            "Epoch 3/3\n",
            "2547/2749 [==========================>...] - ETA: 18s - start_tokens_loss: 0.2717 - loss: 0.5434 - end_tokens_loss: 0.2717"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}